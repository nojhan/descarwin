\documentclass[letterpaper]{article}
\usepackage{aaai}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{url}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PDFMARK for TeX and GhostScript
% Uncomment and complete the following for metadata if
% your paper is typeset using TeX and GhostScript (e.g
% if you use .ps or .eps files in your paper):
% \special{! /pdfmark where
% {pop} {userdict /pdfmark /cleartomark load put} ifelse
% [ /Author (John Doe, Jane Doe)
% /Title (Paper Title)
% /Keywords (AAAI, artificial intelligence)
% /DOCINFO pdfmark}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PDFINFO for PDFTeX
% Uncomment and complete the following for metadata if
% your paper is typeset using PDFTeX
% \pdfinfo{
% /Title (Input Your Title Here)
% /Subject (Input The Proceedings Title Here)
% /Author (First Name, Last Name;
% First Name, Last Name;
% First Name, Last Name;)
% }
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Uncomment only if you need to use section numbers
% and change the 0 to a 1 or 2
% \setcounter{secnumdepth}{0}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Divide-and-Evolve: the Marriage of Descartes and Darwin}
% Please leave SVN version number $Revision: 1131 $

%\author{Blind submission \#14}

\author{Johann Dr{\'e}o \ \ \ \ \ \ Pierre Sav{\'e}ant\\Thales Research \& Technology\\Palaiseau, France\\first.last@thalesgroup.com
\And Marc Schoenauer\\INRIA Saclay \& LRI\\Orsay, France\\marc.schoenauer@inria.fr
\And Vincent Vidal\\ONERA -- DCSD\\ Toulouse, France \\ Vincent.Vidal@onera.fr}


%\newcommand{\spread}{\linespread{0.8}}
\newcommand{\spread}{\linespread{1.0}}
\newcommand{\dae}{{\em Divide-and-Evolve}}
\newcommand{\DAE}{{\sc DaE}}
\newcommand{\DAEX}{{\sc DaE$_{\text{X}}$}}
\newcommand{\DAEYAHSP}{{\sc DaE$_{\text{YAHSP}}$}}
\newcommand{\YAHSP}{{\sc YAHSP}}

\begin{document}
\maketitle

\begin{abstract}
\DAEX, the concrete implementation of the \dae\ paradigm, is a domain-independent satisficing planning system based on Evolutionary Computation.
The basic principle is to carry out a {\em Divide-and-Conquer} strategy driven by an evolutionary algorithm.
The key components of \DAEX\ are a state-based decomposition principle, an evolutionary algorithm to drive the optimization process, and an embedded planner $X$ to solve the sub-problems.
The release that has been submitted to the competition is \DAEYAHSP, the instantiation of \DAEX\ with the
heuristic forward search \YAHSP\ planner.
The marriage of \DAE\ and \YAHSP\ matches a clean role separation:
\YAHSP\ gets a few tries to find a solution quickly whereas \DAE\ controls the optimization process.
\end{abstract}


\section{Introduction}
\DAEX, the concrete implementation of the \dae\ paradigm, is a
domain-independent satisficing planning system based on Evolutionary Computation
\cite{dae:evocop2006}. The basic principle is to carry out a {\em
Divide-and-Conquer} strategy driven by an evolutionary algorithm. The algorithm
is detailed in \cite{dae:icaps2010} and compared with state-of-the-art planners.
In order to solve a planning task ${\cal P}_D(I,G)$, the basic idea of \DAEX\ is
to find a sequence of goals $S_1, \ldots, S_n$, and to rely on an embedded
planner $X$ to solve the series of planning tasks ${\cal P}_D(S_{k},S_{k+1})$,
for $k \in [0,n]$ (with $S_0 = I$ and $S_{n+1} = G$). A \DAEX\ individual is thus a
sequence of goals which define a sequence of subproblems to be solved (a {\it
decomposition}). These subproblems are submitted successively to an embedded
planner $X$ and the global solution is obtained after the compression of these
intermediate solutions. The overall optimization process is controlled by
an evolutionary algorithm.

The decomposition principle of \DAEX\ is very general and could be applied to any type of planning tasks.
The scope of the planner is of course the one of the embedded planner $X$. 
The release that has been submitted to the competition is \DAEYAHSP, the instantiation of \DAEX\ with the
heuristic forward search \YAHSP\ planner \cite{yahsp:icaps2004,yahsp:ipc:2011}.
The target is thus temporal satificing planning with conservative semantics, cost planning and classical STRIPS planning.
The marriage of \DAE\ and \YAHSP\ matches a clean role separation:
\YAHSP\ gets a few tries to find a solution quickly whereas \DAE\ controls the optimization process.
In the current release we have introduced an initial estimation processing of the maximum number of tries allowed to YAHSP for all individual evaluations.
This parameter is crucial for the time consumption of the algorithm.

\section{The Evolutionary Engine}

\begin{figure}[h]
\hskip -1cm
%\includegraphics[width=0.6\textwidth]{DAE.pdf}
%\includegraphics[width=10cm]{DAE.pdf}
\vskip -0.5cm
\caption{The standard evolutionary loop}
\label{fig:daeloop1}
\end{figure}

Figure \ref{fig:daeloop1} depicts the standard evolutionary loop which mimics a biological evolution.
The fitness implements a gradient towards feasibility for unfeasible individuals
and a gradient towards optimality for feasible individuals. Feasible individuals
are always preferred to unfeasible ones. Population initialization as well as
variation operators are driven by the critical path $h^1$ heuristic
\cite{h1:aips2000} in order to discard inconsistent state orderings, and atom
mutual exclusivity inference in order to discard inconsistent states. These two computations are done by YAHSP in an initial phase.

Beside a standard one-point crossover for variable length representations, four mutations
have been defined: addition (resp. removal) of a goal in a sequence, addition (resp. removal) of an atom in a goal. 
Variation operators relax the strictly $h^1$ ordering of atoms within individuals, since it is only a heuristic estimate.

The selection is a comparison-based deterministic tournament of size 5.

% Parameter tuning
For the sequential release, Darwinian-related parameters of \DAEX\ have been
fixed after some early experiments \cite{dae:evocop2006} whereas parameters
related to the variation operators have been tuned using the Racing method
\cite{dae:gecco2010}. It should be noted that, due to the conditions of the competition, the parameter setting is global to all domains. In \cite{dae:gecco2010} we showed that a specific tuning for an instance provides better results as expected and that what we would do for a real-life planning task.

We added two novelties to the version described in
\cite{dae:icaps2010}. One important parameter is the maximum number of expanded
nodes allowed to the \YAHSP\ sub-solver which defines empirically what is
considered as an easy problem for \YAHSP. As a matter of fact, the minimum
number of required nodes varies from few nodes to thousands depending of the
planning task. In the current release this number is estimated during the
population initialization stage. An incremental loop is performed until the
ratio of feasible individuals is over a given threshold or a maximum boundary has
been reached. By default this number is doubled at each iteration until at least
one feasible individual is produced or 100000 has been reached.

Furthermore we add the capability to perform restarts within a time contract in
order to increase solution quality.

The fitness used for the competition differs from the one described in \cite{dae:icaps2010}.
The fitness for bad individuals has been simplified by withdrawing the Hamming distance to the goal.
The new fitness depends only on the ``decomposition distance'': the number of intermediate goals reached and more specifically the one that are ``useful''.
A useful intermediate goal is a goal that require a non-empty plan to be reached.


% Implementation
\section{Implementation}
The implementation of \DAEX\ has been made with the STL-based Evolving
Objects framework\footnote{\url{http://eodev.sf.net}} which provides an abstract
control structure to develop any kind of evolutionary algorithm in C++.
\YAHSP\ is written in the C language.

In  order to  speed up  search, a  memozation mechanism  has been  introduced in
\YAHSP\ and carefully controlled to leave memory space for \DAE. Indeed, most of
the time during a run of \YAHSP, and as a consequence during a run of \DAEYAHSP,
is spent  in computing the $h^{add}$  heuristic for each  encountered state (see
\cite{yahsp:ipc:2011} for more  details about the algorithms of  the new version
of the  \YAHSP\ planner).  During  a single run  of YAHSP, duplicate  states are
discarded;  but during  a run  of \DAEYAHSP,  the same  state can  be encoutered
multiple times.  We therefore keep track  of the $h^{add}$ costs of all atoms in
the problem for each state, in order to avoid recomputing these values each time
a  duplicate state  is reached.   This generally  leads to  a  speedup comprised
between 2  and 4. When  \DAEYAHSP\ runs out  of memory, which  obviously happens
much  faster with  the memoization  strategy, all  stored states  and associated
costs   are  flushed.   More  sophisticated   strategies  may   be  implemented,
e.g. flushing the oldest or less often encountered states; but we found that the
simplest solution  of completely freeing the memoized  information was efficient
enough.

Several  biases have  been introduced  in \YAHSP,  in order  to  help \DAEYAHSP\
finding better  solutions. The main  one is that  actions of lower  duration are
preferred to  break ties  between several actions  of same $h^{add}$  cost, when
computing relaxed plans and performing the relaxed plan repair strategy. Another
bias is  that the  cost incrementation made  during $h^{add}$, which  is usually
equal to 1 for each applied action,  is made equal to either the duration or the
cost of the action. Although these biases do not change a lot the quality of the
plans  produced by  \YAHSP\ alone,  we found  that they  are of  better  help to
\DAEYAHSP. However, introducing such biases is not very satisfactorily; it would
be  better to  exactly use  the version  described in  \cite{yahsp:ipc:2011}. We
still  have to better  investigate the  relationships between  the evolutionnary
engine and the  embedded planner, in order to determine how  to manage such kind
of biases and other tie-breaking strategies.



% the number of remaining goals to solve in the sequence.

% décompositions dont la taille dépasse la longueur max lmax
%return _fitness_penalty * ((double)_l_max + 1.0) * (double)_l_max * (double)_unknown_parameter * 2; 

% echec avant la dernière station
%return _fitness_penalty * ((double)_l_max -(double)decompo.get_number_useful_goals() + 1.0) * (double)_l_max * (double)_unknown_parameter;

% Echec à la dernière station
%return _fitness_penalty * ((double)_l_max -(double)decompo.get_number_useful_goals() + 1.0); }

\section{Conclusion}

\section{Acknowledgments}
This work is being partially funded by the French National Research Agency (ANR) through the COSINUS programme, under the research contract DESCARWIN (ANR-09-COSI-002).


\bibliographystyle{aaai}
\bibliography{dae_mt}


\end{document}





